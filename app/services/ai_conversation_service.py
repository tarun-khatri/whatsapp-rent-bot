"""
AI Conversation Service

This service handles AI-generated responses for both tenant and guarantor conversations.
It provides natural, human-like responses while maintaining conversation flow logic.
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import json

from app.services.vertex_ai_service import vertex_ai_service

logger = logging.getLogger(__name__)


class AIConversationService:
    """Service for generating AI-powered conversation responses."""
    
    def __init__(self):
        self.vertex_ai_service = vertex_ai_service
    
    async def generate_media_error_response(self, phone_number: str, user_message: str, 
                                           error_context: Dict[str, Any]) -> str:
        """
        Generate AI response for media download failures.
        
        Args:
            phone_number: User's phone number
            user_message: User's original message
            error_context: Context about the error
            
        Returns:
            AI-generated error response in Hebrew
        """
        try:
            logger.info("Generating AI media error response", extra={
                "phone_number": phone_number,
                "error_type": error_context.get("error_type"),
                "retry_attempts": error_context.get("retry_attempts")
            })
            
            # Build AI prompt for media error based on error type
            error_type = error_context.get('error_type', 'media_download_failed')
            retry_attempts = error_context.get('retry_attempts', 0)
            
            if error_type == "webhook_media_download_failed":
                # This is from WhatsApp's webhook - likely file format issue
                suggestions = error_context.get('suggestions', [])
                suggestions_text = "\n".join([f"â€¢ {suggestion}" for suggestion in suggestions]) if suggestions else ""
                
                prompt = f"""
××ª×” ×™×•× ×™ ×ž×ž×’×•×¨×™×ª, ×¢×•×–×¨ × ×“×œ×Ÿ ×™×“×™×“×•×ª×™.

×”×ž×©×ª×ž×© ×©×œ×— ×§×•×‘×¥ (×ª×ž×•× ×”/×ž×¡×ž×š) ××‘×œ WhatsApp ×œ× ×”×¦×œ×™×— ×œ×¢×‘×“ ××•×ª×•.

×”×ž×¦×‘:
- ×–×” ×œ× ×‘×¢×™×” ×‘×ž×¢×¨×›×ª ×©×œ× ×•
- WhatsApp ×œ× ×”×¦×œ×™×— ×œ×¢×‘×“ ××ª ×”×§×•×‘×¥
- ×–×” ×™×›×•×œ ×œ×”×™×•×ª ×‘×’×œ×œ ×¤×•×¨×ž×˜ ×”×§×•×‘×¥ ××• ×’×•×“×œ×•

×”×•×¨××•×ª:
- ×”×¡×‘×¨ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª ×ž×” ×§×¨×”
- ××œ ×ª××©×™× ××ª ×”×ž×¢×¨×›×ª ×©×œ× ×•
- ×ª×Ÿ ×˜×™×¤×™× ×ž×¢×©×™×™× ×œ×©×™×¤×•×¨:
{suggestions_text}
- ×‘×§×© ×ž×”×ž×©×ª×ž×© ×œ× ×¡×•×ª ×©×•×‘ ×¢× ×ª×ž×•× ×” ××—×¨×ª
- ×”×™×” ××ž×¤×ª×™ ×•×ž×•×¢×™×œ
- ×”×¦×¢ ×—×œ×•×¤×”: ×œ×›×ª×•×‘ ×‘×ž×™×œ×™× ×ž×” ×¨×¦×” ×œ×©×œ×•×—

×ª×’×•×‘×” ×§×¦×¨×” ×•×ž×•×¢×™×œ×”:
"""
            else:
                # Regular media download failure
                prompt = f"""
××ª×” ×™×•× ×™ ×ž×ž×’×•×¨×™×ª, ×¢×•×–×¨ × ×“×œ×Ÿ ×™×“×™×“×•×ª×™.

×”×ž×©×ª×ž×© ×©×œ×— ×§×•×‘×¥ (×ª×ž×•× ×”/×ž×¡×ž×š) ××‘×œ ×œ× ×”×¦×œ×—×ª×™ ×œ×”×•×¨×™×“ ××•×ª×•.

×¤×¨×˜×™ ×”×©×’×™××”:
- × ×™×¡×™×ª×™ {retry_attempts} ×¤×¢×ž×™× ×œ×”×•×¨×™×“
- ×”×‘×¢×™×” ×™×›×•×œ×” ×œ×”×™×•×ª ×‘×¨×©×ª ××• ×‘-WhatsApp
- ×”×•×“×¢×” ×ž×§×•×¨×™×ª: {user_message}

×”×•×¨××•×ª:
- ×”×¡×‘×¨ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª ×ž×” ×§×¨×”
- ×‘×§×© ×ž×”×ž×©×ª×ž×© ×œ× ×¡×•×ª ×œ×©×œ×•×— ×©×•×‘
- ×ª×Ÿ ×˜×™×¤: ××•×œ×™ ×œ×—×›×•×ª ×“×§×” ×•×œ× ×¡×•×ª ×©×•×‘
- ×”×™×” ××ž×¤×ª×™ ×•×ž×•×¢×™×œ
- ××œ ×ª×¦×™×’ ××ª ×¢×¦×ž×š ×©×•×‘
- ×”×©×ª×ž×© ×‘×˜×•×Ÿ ×—× ××‘×œ ×ž×§×¦×•×¢×™
- ×”×¦×¢ ×—×œ×•×¤×”: ×œ×›×ª×•×‘ ×‘×ž×™×œ×™× ×ž×” ×¨×¦×” ×œ×©×œ×•×—

×ª×’×•×‘×” ×§×¦×¨×” ×•×ž×•×¢×™×œ×”:
"""
            
            # Generate AI response
            ai_response = await self.vertex_ai_service.generate_response(prompt)
            
            # Apply WhatsApp formatting
            formatted_response = self.vertex_ai_service._format_ai_response_for_whatsapp(ai_response)
            
            logger.info("AI media error response generated successfully", extra={
                "phone_number": phone_number,
                "response_length": len(formatted_response)
            })
            
            return formatted_response
            
        except Exception as e:
            logger.error("Error generating AI media error response", extra={
                "phone_number": phone_number,
                "error": str(e)
            })
            # Fallback response
            return "×ž×¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×”×•×¨×™×“ ××ª ×”×§×•×‘×¥. ×–×” ×‘×¢×™×” ×–×ž× ×™×ª ×©×œ WhatsApp. ×× × × ×¡×” ×œ×©×œ×•×— ×©×•×‘ ×‘×¢×•×“ ×›×ž×” ×“×§×•×ª."

    async def generate_response(self, phone_number: str, user_message: str, 
                              conversation_type: str, current_state: str, 
                              context_data: Dict[str, Any]) -> str:
        """
        Generate AI response for both tenants and guarantors using enhanced human-like responses.
        
        Args:
            phone_number: User's phone number
            user_message: User's message
            conversation_type: 'tenant' or 'guarantor'
            current_state: Current conversation state
            context_data: Context data from conversation state
            
        Returns:
            AI-generated response in Hebrew with human-like tone and proper formatting
        """
        try:
            logger.info("Generating enhanced AI response", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "current_state": current_state,
                "context_data": context_data
            })
            
            # Get conversation history (simplified approach)
            conversation_history = await self._get_simple_conversation_history(phone_number, conversation_type)
            
            # Use the new enhanced human-like AI response generation
            ai_response = await self.vertex_ai_service.generate_human_like_response(
                conversation_type=conversation_type,
                current_state=current_state,
                context_data=context_data,
                user_message=user_message,
                conversation_history=conversation_history
            )
            
            # Store the AI response in conversation history (simplified)
            await self._store_simple_message_history(
                phone_number, conversation_type, "bot_response", ai_response, current_state
            )
            
            logger.info("Enhanced AI response generated successfully", extra={
                "phone_number": phone_number,
                "response_length": len(ai_response)
            })
            
            return ai_response
            
        except Exception as e:
            logger.error("Error generating enhanced AI response", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            # Fallback to default response
            return self._get_safe_fallback_response(conversation_type, current_state)

    async def _get_simple_conversation_history(self, phone_number: str, conversation_type: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Get simple conversation history for AI context."""
        try:
            # Try to use supabase service if available
            from app.services.supabase_service import supabase_service
            
            result = supabase_service.client.rpc(
                'get_conversation_history_for_ai',
                {
                    'p_phone_number': phone_number,
                    'p_conversation_type': conversation_type,
                    'p_limit': limit
                }
            ).execute()
            
            if result.data:
                return result.data
            return []
            
        except Exception as e:
            logger.error("Error getting conversation history", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            return []

    async def _store_simple_message_history(self, phone_number: str, conversation_type: str, 
                                          message_type: str, content: str, state: str):
        """Store message in conversation history."""
        try:
            from app.services.supabase_service import supabase_service
            
            history_data = {
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "message_type": message_type,
                "message_content": content,
                "conversation_state": state,
                "context_data": {},
                "message_timestamp": datetime.now().isoformat()
            }
            
            supabase_service.client.table("conversation_history").insert(history_data).execute()
            
        except Exception as e:
            logger.error("Error storing message history", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })

    def _get_safe_fallback_response(self, conversation_type: str, current_state: str) -> str:
        """Get safe fallback response when AI fails completely."""
        fallback_responses = {
            "tenant": {
                "GREETING": "×©×œ×•×! ×× ×™ ×™×•× ×™ ×ž×ž×’×•×¨×™×ª ðŸ˜Š\n\n×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š ×¢× ×”×ª×”×œ×™×š. ××™×š ×× ×™ ×™×›×•×œ ×œ×¡×™×™×¢?",
                "CONFIRMATION": "×× × ××©×¨ ××ª ×”×¤×¨×˜×™× ×©×™×© ×œ×™ ðŸ“‹\n\n**×”×× ×”×¤×¨×˜×™× × ×›×•× ×™×?**",
                "PERSONAL_INFO": "×× ×™ ×¦×¨×™×š ×¢×•×“ ×§×¦×ª ×ž×™×“×¢ ××™×©×™ ðŸ“\n\n**×ž×” ×”×¢×™×¡×•×§ ×©×œ×š?**",
                "DOCUMENTS": "×¢×›×©×™×• ×× ×™ ×¦×¨×™×š ×ž×¡×ž×›×™× ðŸ“„\n\n**×ª×•×›×œ ×œ×©×œ×•×— ××ª ×ª×¢×•×“×ª ×”×–×”×•×ª ×©×œ×š?**",
                "GUARANTOR_1": "×× ×™ ×¦×¨×™×š ×¤×¨×˜×™ ×¢×¨×‘ ×¨××©×•×Ÿ ðŸ‘¥\n\n**×ž×” ×”×©× ×”×ž×œ× ×©×œ ×”×¢×¨×‘ ×”×¨××©×•×Ÿ?**",
                "GUARANTOR_2": "×× ×™ ×¦×¨×™×š ×¤×¨×˜×™ ×¢×¨×‘ ×©× ×™ ðŸ‘¥\n\n**×ž×” ×”×©× ×”×ž×œ× ×©×œ ×”×¢×¨×‘ ×”×©× ×™?**",
                "COMPLETED": "×ž×¢×•×œ×”! ×”×ª×”×œ×™×š ×”×•×©×œ× ×‘×”×¦×œ×—×” ðŸŽ‰\n\n×ª×•×“×” ×¢×œ ×©×™×ª×•×£ ×”×¤×¢×•×œ×”!"
            },
            "guarantor": {
                "GREETING": "×©×œ×•×! ×× ×™ ×™×•× ×™ ×ž×ž×’×•×¨×™×ª ðŸ˜Š\n\n×× ×™ ×¦×¨×™×š ××ª ×”×ž×¡×ž×›×™× ×©×œ×š ×›×¢×¨×‘. × ×ª×—×™×œ?",
                "DOCUMENTS": "×× ×™ ×¦×¨×™×š ××ª ×”×ž×¡×ž×›×™× ×©×œ×š ðŸ“„\n\n**×ª×•×›×œ ×œ×©×œ×•×— ××ª ×ª×¢×•×“×ª ×”×–×”×•×ª ×©×œ×š?**",
                "COMPLETED": "×ž×¢×•×œ×”! ×›×œ ×”×ž×¡×ž×›×™× ×”×ª×§×‘×œ×• ðŸŽ‰\n\n×ª×•×“×” ×¢×œ ×©×™×ª×•×£ ×”×¤×¢×•×œ×”!"
            }
        }
        
        return fallback_responses.get(conversation_type, {}).get(current_state, 
            "×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š ðŸ˜Š\n\n×ª×•×›×œ ×œ×¡×¤×¨ ×œ×™ ××™×š ×× ×™ ×™×›×•×œ ×œ×¡×™×™×¢?")
    
    async def _get_conversation_history(self, phone_number: str, conversation_type: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Get conversation history for AI context."""
        try:
            # Use the database function to get conversation history
            result = self.supabase_service.client.rpc(
                'get_conversation_history_for_ai',
                {
                    'p_phone_number': phone_number,
                    'p_conversation_type': conversation_type,
                    'p_limit': limit
                }
            ).execute()
            
            if result.data:
                return result.data
            return []
            
        except Exception as e:
            logger.error("Error getting conversation history", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            return []
    
    async def _get_conversation_history_with_token_limit(self, phone_number: str, conversation_type: str, max_tokens: int = 50000) -> List[Dict[str, Any]]:
        """Get conversation history with token limit to prevent AI overload."""
        try:
            # Start with a small limit and increase if needed
            limit = 3
            total_tokens = 0
            history = []
            
            while limit <= 10 and total_tokens < max_tokens:
                result = self.supabase_service.client.rpc(
                    'get_conversation_history_for_ai',
                    {
                        'p_phone_number': phone_number,
                        'p_conversation_type': conversation_type,
                        'p_limit': limit
                    }
                ).execute()
                
                if not result.data:
                    break
                
                # Calculate approximate token count (rough estimate: 1 token â‰ˆ 4 characters)
                new_history = result.data
                new_tokens = sum(len(str(msg.get('message_content', ''))) * 0.25 for msg in new_history)
                
                if total_tokens + new_tokens > max_tokens:
                    break
                
                history = new_history
                total_tokens += new_tokens
                limit += 2
            
            logger.info("Conversation history retrieved", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "message_count": len(history),
                "estimated_tokens": total_tokens
            })
            
            return history
            
        except Exception as e:
            logger.error("Error getting conversation history with token limit", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            return []
    
    async def _get_conversation_personality(self, phone_number: str, conversation_type: str) -> Dict[str, Any]:
        """Get conversation personality data."""
        try:
            if conversation_type == "tenant":
                conversation_state = await self.supabase_service.get_conversation_state(phone_number)
                if conversation_state:
                    return conversation_state.conversation_personality or {}
            elif conversation_type == "guarantor":
                conversation_state = await self.supabase_service.get_guarantor_conversation_state(phone_number)
                if conversation_state:
                    return conversation_state.get("conversation_personality", {})
            
            return {}
            
        except Exception as e:
            logger.error("Error getting conversation personality", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            return {}
    
    async def _build_ai_prompt(self, conversation_type: str, current_state: str, 
                             context_data: Dict[str, Any], conversation_history: List[Dict], 
                             personality: Dict[str, Any], user_message: str) -> str:
        """Build AI prompt based on conversation type."""
        
        if conversation_type == "tenant":
            return await self._build_tenant_prompt(current_state, context_data, conversation_history, personality, user_message)
        elif conversation_type == "guarantor":
            return await self._build_guarantor_prompt(current_state, context_data, conversation_history, personality, user_message)
        else:
            raise ValueError(f"Unknown conversation type: {conversation_type}")
    
    async def _build_tenant_prompt(self, current_state: str, context_data: Dict[str, Any], 
                                 conversation_history: List[Dict], personality: Dict[str, Any], 
                                 user_message: str) -> str:
        """Build AI prompt for tenant conversations."""
        
        # Format conversation history
        history_text = self._format_conversation_history(conversation_history)
        
        # Get tenant context
        tenant_name = context_data.get('tenant_name', '×”×“×™×™×¨')
        property_name = context_data.get('property_name', '×”× ×›×¡')
        apartment_number = context_data.get('apartment_number', '')
        
        # Get personality traits
        formality_level = personality.get('formality_level', 'professional_friendly')
        response_style = personality.get('response_style', 'helpful')
        
        # Get current task description
        current_task = self._get_tenant_task_description(current_state, context_data)
        
        prompt = f"""
××ª×” ×™×•× ×™ ×ž×ž×’×•×¨×™×ª, ×¢×•×–×¨ × ×“×œ×Ÿ ×™×“×™×“×•×ª×™ ×©×ž×¡×™×™×¢ ×œ×“×™×™×¨×™×.

×”×§×©×¨:
- ×“×™×™×¨: {tenant_name}
- × ×›×¡: {property_name}
- ×“×™×¨×”: {apartment_number}
- ×ž×¦×‘: {current_state}

×”×™×¡×˜×•×¨×™×”:
{history_text}

×ž×©×™×ž×”: {current_task}

×”×•×“×¢×”: {user_message}

×”×•×¨××•×ª:
- ×”×©×‘ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª, ×›××™×œ×• ××ª×” ×ž×“×‘×¨ ×¢× ×—×‘×¨
- ××œ ×ª×—×–×•×¨ ×¢×œ ×ž×” ×©×”×ž×©×ª×ž×© ××ž×¨
- ××œ ×ª×¦×™×’ ××ª ×¢×¦×ž×š ×©×•×‘
- ×”×©×ª×ž×© ×‘×©×ž×•×ª ××ž×™×ª×™×™×
- ×”×™×” ×™×©×™×¨ ×•×ž×•×¢×™×œ
- ×©×ž×•×¨ ×¢×œ ×˜×•×Ÿ ×—× ××‘×œ ×œ× ×¨×©×ž×™
- ××œ ×ª×—×–×•×¨ ×¢×œ ×ž×™×“×¢ ×©×›×‘×¨ × ××ž×¨
"""
        
        return prompt
    
    async def _build_guarantor_prompt(self, current_state: str, context_data: Dict[str, Any], 
                                    conversation_history: List[Dict], personality: Dict[str, Any], 
                                    user_message: str) -> str:
        """Build AI prompt for guarantor conversations."""
        
        # Format conversation history
        history_text = self._format_conversation_history(conversation_history)
        
        # Get guarantor context
        guarantor_name = context_data.get('guarantor_name', '×”×¢×¨×‘')
        tenant_name = context_data.get('tenant_name', '×”×“×™×™×¨')
        property_name = context_data.get('property_name', '×”× ×›×¡')
        current_document = context_data.get('current_document', '×ª×¢×•×“×ª ×–×”×•×ª')
        collected_documents = context_data.get('collected_documents', [])
        pending_documents = context_data.get('pending_documents', [])
        document_status = context_data.get('document_status', {})
        
        # Get personality traits
        formality_level = personality.get('formality_level', 'professional_friendly')
        response_style = personality.get('response_style', 'helpful')
        
        # Get current task description
        current_task = self._get_guarantor_task_description(current_state, context_data)
        
        # Format document status information
        status_info = ""
        if collected_documents:
            status_info += f"\n×ž×¡×ž×›×™× ×©×›×‘×¨ ×”×ª×§×‘×œ×• ×•××•×©×¨×•: {', '.join(collected_documents)}"
        if pending_documents:
            status_info += f"\n×ž×¡×ž×›×™× ×©× ×•×ª×¨×•: {', '.join(pending_documents)}"
        
        # Add explicit instruction about not asking for already collected documents
        if collected_documents:
            status_info += f"\n×—×©×•×‘: ××œ ×ª×‘×§×© ×ž×¡×ž×›×™× ×©×›×‘×¨ ×”×ª×§×‘×œ×• ×•××•×©×¨×•! ×”×ž×¡×ž×›×™× ×”×‘××™× ×›×‘×¨ ××•×©×¨×•: {', '.join(collected_documents)}"
        
        # Check if a document was just approved
        document_just_approved = context_data.get('document_just_approved', False)
        next_document = context_data.get('next_document', '')
        print(f"DEBUG AI: document_just_approved={document_just_approved}, next_document={next_document}")
        if document_just_approved and next_document:
            # Map document types to Hebrew names
            document_names = {
                "id_card": "×ª×¢×•×“×ª ×”×–×”×•×ª",
                "sephach": "×”×¡×¤×—",
                "payslips": "×ª×œ×•×©×™ ×”×ž×©×›×•×¨×ª",
                "bank_statements": "×“×•×— ×”×‘× ×§",
                "pnl": "×“×•×— ×¨×•×•×— ×•×”×¤×¡×“"
            }
            next_document_name = document_names.get(next_document, next_document)
            status_info += f"\n×—×©×•×‘: ×ž×¡×ž×š {current_document} ×–×” ×¢×ª×” ××•×©×¨! ×¢×›×©×™×• ×‘×§×© ××ª {next_document_name}."
            print(f"DEBUG AI: Added status_info: {status_info}")
        
        # Check if a document was just rejected
        document_just_rejected = context_data.get('document_just_rejected', False)
        rejection_reason = context_data.get('rejection_reason', '')
        current_document = context_data.get('current_document', 'id_card')
        print(f"DEBUG AI: document_just_rejected={document_just_rejected}, rejection_reason={rejection_reason}, current_document={current_document}")
        if document_just_rejected:
            # Extract the actual document type from the rejection reason
            # Format: "×”×ž×¡×ž×š ×œ× ××•×©×¨. ... ×× × ×©×œ×— ×©×•×‘ ××ª payslips."
            rejected_document_type = "unknown"
            if "×× × ×©×œ×— ×©×•×‘ ××ª" in rejection_reason:
                parts = rejection_reason.split("×× × ×©×œ×— ×©×•×‘ ××ª ")
                if len(parts) > 1:
                    rejected_document_type = parts[1].split(".")[0].strip()
            elif "×× × ×©×œ×— ×ž×¡×ž×š" in rejection_reason:
                # This is the generic message when no document was sent
                # Use the current document from context
                rejected_document_type = current_document
                print(f"DEBUG AI: Using current_document as rejected_document_type: {rejected_document_type}")
            
            # Map document types to Hebrew names
            document_names = {
                "id_card": "×ª×¢×•×“×ª ×”×–×”×•×ª",
                "sephach": "×”×¡×¤×—", 
                "payslips": "×ª×œ×•×©×™ ×”×ž×©×›×•×¨×ª",
                "bank_statements": "×“×•×— ×”×‘× ×§",
                "pnl": "×“×•×— ×¨×•×•×— ×•×”×¤×¡×“"
            }
            rejected_document_name = document_names.get(rejected_document_type, rejected_document_type)
            
            # Include specific validation errors in the status info
            if rejected_document_type != "unknown":
                # Extract specific errors from rejection reason
                specific_errors = rejection_reason.replace("×”×ž×¡×ž×š ×œ× ××•×©×¨. ", "").replace(f" ×× × ×©×œ×— ×©×•×‘ ××ª {rejected_document_type}.", "")
                if specific_errors.strip():
                    status_info += f"\n×—×©×•×‘: ×”×ž×¡×ž×š {rejected_document_name} × ×“×—×”! ×”×¡×™×‘×•×ª: {specific_errors.strip()}. ×‘×§×© ××ª ××•×ª×• ×ž×¡×ž×š ×©×•×‘ ×¢× ×”×ž×™×“×¢ ×”× ×›×•×Ÿ."
                else:
                    status_info += f"\n×—×©×•×‘: ×”×ž×¡×ž×š {rejected_document_name} × ×“×—×”! ×‘×§×© ××ª ××•×ª×• ×ž×¡×ž×š ×©×•×‘ ×¢× ×”×ž×™×“×¢ ×”× ×›×•×Ÿ."
            else:
                status_info += f"\n×—×©×•×‘: ×”×ž×¡×ž×š {rejected_document_name} × ×“×—×”! ×‘×§×© ××ª ××•×ª×• ×ž×¡×ž×š ×©×•×‘ ×¢× ×”×ž×™×“×¢ ×”× ×›×•×Ÿ."
            print(f"DEBUG AI: Added rejection status_info: {status_info}")
        
        # Add specific validation errors to the prompt if available
        validation_errors = ""
        if document_just_rejected and rejection_reason:
            # Extract validation errors from rejection reason
            if "×”×ž×¡×ž×š ×œ× ××•×©×¨." in rejection_reason:
                error_part = rejection_reason.split("×”×ž×¡×ž×š ×œ× ××•×©×¨. ")[1]
                if "×× × ×©×œ×— ×©×•×‘ ××ª" in error_part:
                    error_part = error_part.split("×× × ×©×œ×— ×©×•×‘ ××ª")[0].strip()
                if error_part:
                    validation_errors = f"\n\n×¤×¨×˜×™ ×”×©×’×™××•×ª: {error_part}"
                    print(f"DEBUG AI: Extracted validation errors: {error_part}")

        prompt = f"""
××ª×” ×™×•× ×™ ×ž×ž×’×•×¨×™×ª, ×¢×•×–×¨ × ×“×œ×Ÿ ×©×ž×¡×™×™×¢ ×œ×¢×¨×‘×™×.

×”×§×©×¨:
- ×¢×¨×‘: {guarantor_name}
- ×“×™×™×¨: {tenant_name}
- × ×›×¡: {property_name}
- ×ž×¡×ž×š × ×•×›×—×™: {current_document}
- ×ž×¦×‘: {current_state}
{status_info}

×”×™×¡×˜×•×¨×™×”:
{history_text}

×ž×©×™×ž×”: {current_task}

×”×•×“×¢×”: {user_message}

×”×•×¨××•×ª ×—×©×•×‘×•×ª:
- ×”×©×‘ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª, ×›××™×œ×• ××ª×” ×ž×“×‘×¨ ×¢× ×—×‘×¨
- ××œ ×ª×—×–×•×¨ ×¢×œ ×ž×” ×©×”×ž×©×ª×ž×© ××ž×¨
- ××œ ×ª×¦×™×’ ××ª ×¢×¦×ž×š ×©×•×‘
- ×”×©×ª×ž×© ×‘×©×ž×•×ª ××ž×™×ª×™×™×
- ×”×™×” ×™×©×™×¨ ×•×ž×•×¢×™×œ
- ×©×ž×•×¨ ×¢×œ ×˜×•×Ÿ ×—× ××‘×œ ×œ× ×¨×©×ž×™
- ××œ ×ª×—×–×•×¨ ×¢×œ ×ž×™×“×¢ ×©×›×‘×¨ × ××ž×¨
- ×”×™×” ×ž×•×“×¢ ×œ×ž×¦×‘ ×”× ×•×›×—×™ ×©×œ ×”×ž×¡×ž×›×™×
- ××œ ×ª×ª×—×™×œ ×”×•×“×¢×•×ª ×¢× "×”×™×™" ××• "×©×œ×•×" - ×¨×§ ×‘×¤×¢× ×”×¨××©×•× ×”

×—×©×•×‘ ×ž××•×“ - ×¡×“×¨ ×”×ž×¡×ž×›×™×:
- ×‘×§×© ×¨×§ ××ª ×”×ž×¡×ž×š ×”× ×•×›×—×™: {current_document}
- ××œ ×ª×¦×™×¢ ×ž×¡×ž×›×™× ××—×¨×™×
- ××œ ×ª×“×œ×’ ×¢×œ ×ž×¡×ž×›×™×
- ×× ×”×ž×©×ª×ž×© ×©×•×œ×— ×ž×¡×ž×š ××—×¨, ×”×¡×‘×¨ ×©×¦×¨×™×š ××ª ×”×ž×¡×ž×š ×”× ×•×›×—×™ ×§×•×“×
- ×©×ž×•×¨ ×¢×œ ×”×¡×“×¨ ×”×ž×“×•×™×§ ×©×œ ×”×ž×¡×ž×›×™×

×—×©×•×‘ ×ž××•×“ - ××œ ×ª×‘×§×© ×ž×¡×ž×›×™× ×©×›×‘×¨ ××•×©×¨×•:
- ×× ×ª×¢×•×“×ª ×–×”×•×ª ×›×‘×¨ ××•×©×¨×”, ××œ ×ª×‘×§×© ××•×ª×” ×©×•×‘
- ×× ×¡×¤×— ×›×‘×¨ ××•×©×¨, ××œ ×ª×‘×§×© ××•×ª×• ×©×•×‘
- ×‘×§×© ×¨×§ ××ª ×”×ž×¡×ž×š ×”×‘× ×‘×¡×“×¨
- ×× ×›×œ ×”×ž×¡×ž×›×™× ××•×©×¨×•, ×”×•×“×¢ ×©×”×ª×”×œ×™×š ×”×•×©×œ×

×—×©×•×‘ ×ž××•×“ - ×–×” ×¢×¨×‘, ×œ× ×“×™×™×¨:
- ××ª×” ×ž×“×‘×¨ ×¢× {guarantor_name} ×©×”×•× ×¢×¨×‘ ×¢×‘×•×¨ {tenant_name}
- ×‘×§×© ×ž×”×¢×¨×‘ ××ª ×”×ž×¡×ž×›×™× ×©×œ×•, ×œ× ×©×œ ×”×“×™×™×¨
- ××œ ×ª×‘×§×© ×ž×”×¢×¨×‘ ×œ×©×œ×•×— ×ž×¡×ž×›×™× ×©×œ ×”×“×™×™×¨
- ×”×¢×¨×‘ ×¦×¨×™×š ×œ×©×œ×•×— ××ª ×”×ž×¡×ž×›×™× ×©×œ×• ×¢×¦×ž×•
{validation_errors}
"""
        
        return prompt
    
    def _format_conversation_history(self, history: List[Dict[str, Any]]) -> str:
        """Format conversation history for AI context."""
        if not history:
            return "××™×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×§×•×“×ž×ª."
        
        formatted_history = []
        for entry in reversed(history):  # Reverse to show chronological order
            message_type = "×ž×©×ª×ž×©" if entry.get('message_type') == 'user' else "×‘×•×˜"
            content = entry.get('message_content', '')
            timestamp = entry.get('timestamp', '')
            
            formatted_history.append(f"{message_type}: {content}")
        
        return "\n".join(formatted_history)
    
    def _get_tenant_task_description(self, current_state: str, context_data: Dict[str, Any]) -> str:
        """Get task description for tenant conversations."""
        task_descriptions = {
            "GREETING": "×‘×¨×›×” ×œ×“×™×™×¨ ×”×—×“×© ×•×”×¦×’×ª ×”×ª×”×œ×™×š",
            "CONFIRMATION": "××™×©×•×¨ ×¤×¨×˜×™ ×”× ×›×¡ ×•×”×“×™×™×¨",
            "PERSONAL_INFO": "××™×¡×•×£ ×ž×™×“×¢ ××™×©×™ (×¢×™×¡×•×§, ×ž×¦×‘ ×ž×©×¤×—×ª×™, ×ž×¡×¤×¨ ×™×œ×“×™×)",
            "DOCUMENTS": "××™×¡×•×£ ×ž×¡×ž×›×™× × ×“×¨×©×™× (×ª×¢×•×“×ª ×–×”×•×ª, ×¡×¤×—, ×ª×œ×•×©×™ ×©×›×¨, ×“×•×—×•×ª ×‘× ×§)",
            "GUARANTOR_1": "××™×¡×•×£ ×¤×¨×˜×™ ×¢×¨×‘ ×¨××©×•×Ÿ",
            "GUARANTOR_2": "××™×¡×•×£ ×¤×¨×˜×™ ×¢×¨×‘ ×©× ×™",
            "COMPLETED": "×¡×™×•× ×”×ª×”×œ×™×š ×•××™×©×•×¨ ×§×‘×œ×”"
        }
        
        return task_descriptions.get(current_state, "×ž×©×™×ž×” ×œ× ×ž×•×’×“×¨×ª")
    
    def _get_guarantor_task_description(self, current_state: str, context_data: Dict[str, Any]) -> str:
        """Get task description for guarantor conversations."""
        current_document = context_data.get('current_document', '×ž×¡×ž×š')
        
        # Define the complete document list in order
        document_list = [
            "×ª×¢×•×“×ª ×–×”×•×ª",
            "×¡×¤×— ×ª×¢×•×“×ª ×–×”×•×ª", 
            "×ª×œ×•×©×™ ×©×›×¨ (3 ×—×•×“×©×™× ××—×¨×•× ×™×)",
            "×“×•×— ×‘× ×§ (3 ×—×•×“×©×™× ××—×¨×•× ×™×)",
            "××™×©×•×¨ ×”×›× ×¡×”"
        ]
        
        task_descriptions = {
            "GREETING": "×‘×¨×›×” ×œ×¢×¨×‘ ×•×”×¦×’×ª ×”×ª×”×œ×™×š",
            "DOCUMENTS": f"××™×¡×•×£ {current_document} - ×¨×§ ×”×ž×¡×ž×š ×”× ×•×›×—×™, ×œ× ××—×¨",
            "COMPLETED": "×¡×™×•× ××™×¡×•×£ ×”×ž×¡×ž×›×™×"
        }
        
        base_task = task_descriptions.get(current_state, "×ž×©×™×ž×” ×œ× ×ž×•×’×“×¨×ª")
        
        if current_state == "DOCUMENTS":
            return f"{base_task}\n\n×¨×©×™×ž×ª ×ž×¡×ž×›×™× × ×“×¨×©×™× (×‘×¡×“×¨):\n" + "\n".join([f"{i+1}. {doc}" for i, doc in enumerate(document_list)])
        
        return base_task
    
    async def _store_message_history(self, phone_number: str, conversation_type: str, 
                                   message_type: str, content: str, state: str, 
                                   context_data: Dict[str, Any] = None):
        """Store message in conversation history."""
        try:
            history_data = {
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "message_type": message_type,
                "message_content": content,
                "conversation_state": state,
                "context_data": context_data or {},
                "message_timestamp": datetime.now().isoformat()
            }
            
            self.supabase_service.client.table("conversation_history").insert(history_data).execute()
            
        except Exception as e:
            logger.error("Error storing message history", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
    
    async def _get_fallback_response(self, conversation_type: str, current_state: str) -> str:
        """Get fallback response when AI fails."""
        fallback_responses = {
            "tenant": {
                "GREETING": "×©×œ×•×! ×× ×™ ×™×•× ×™ ×ž×ž×’×•×¨×™×ª. ××™×š ×× ×™ ×™×›×•×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?",
                "CONFIRMATION": "×× × ××©×¨ ××ª ×”×¤×¨×˜×™× ×©×¦×•×™× ×•.",
                "PERSONAL_INFO": "×× × ×©×œ×— ××ª ×”×ž×™×“×¢ ×”× ×“×¨×©.",
                "DOCUMENTS": "×× × ×©×œ×— ××ª ×”×ž×¡×ž×›×™× ×”× ×“×¨×©×™×.",
                "GUARANTOR_1": "×× × ×©×œ×— ××ª ×¤×¨×˜×™ ×”×¢×¨×‘ ×”×¨××©×•×Ÿ.",
                "GUARANTOR_2": "×× × ×©×œ×— ××ª ×¤×¨×˜×™ ×”×¢×¨×‘ ×”×©× ×™.",
                "COMPLETED": "×ª×•×“×”! ×”×ª×”×œ×™×š ×”×•×©×œ× ×‘×”×¦×œ×—×”."
            },
            "guarantor": {
                "GREETING": "×©×œ×•×! ×× ×™ ×™×•× ×™ ×ž×ž×’×•×¨×™×ª. ××™×š ×× ×™ ×™×›×•×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?",
                "DOCUMENTS": "×× × ×©×œ×— ××ª ×”×ž×¡×ž×›×™× ×”× ×“×¨×©×™×.",
                "COMPLETED": "×ª×•×“×”! ×”×ª×”×œ×™×š ×”×•×©×œ× ×‘×”×¦×œ×—×”."
            }
        }
        
        return fallback_responses.get(conversation_type, {}).get(current_state, "×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š. ××™×š ×× ×™ ×™×›×•×œ ×œ×¡×™×™×¢?")
    
    async def update_conversation_personality(self, phone_number: str, conversation_type: str, 
                                            personality_data: Dict[str, Any]) -> bool:
        """Update conversation personality based on user interactions."""
        try:
            # Use the database function to update personality
            result = self.supabase_service.client.rpc(
                'update_conversation_personality',
                {
                    'p_phone_number': phone_number,
                    'p_conversation_type': conversation_type,
                    'p_personality_data': personality_data
                }
            ).execute()
            
            return True
            
        except Exception as e:
            logger.error("Error updating conversation personality", extra={
                "phone_number": phone_number,
                "conversation_type": conversation_type,
                "error": str(e)
            })
            return False


# Global instance
ai_conversation_service = AIConversationService()
